name: Eike Steffen Kohlmeyer
jobTitle: Machine Learning Engineer
location: Munich, Germany
about: >
  Passionate team player experienced in applied Machine Learning,
  particularly NLP. My experience spans the entire MLOps lifecycle, and I
  am experienced in the application of Large Language Models. My high
  intrinsic motivation, skillset, and solution-oriented work style make me
  an excellent fit for your projects.
contacts:
  email: ekohlmeyer21@gmail.com
  linkedin: https://www.linkedin.com/in/eike-kohlmeyer
  github: https://github.com/EikeKohl
  website: https://kohlmeyer-ai.com
  medium: https://medium.com/@EKohlmeyer

technologies:
  - Python
  - SQL
  - scikit-learn
  - NumPy
  - Pandas
  - TensorFlow
  - PyTorch
  - Git
  - Docker
  - Linux
  - AWS
  - Azure
  - dbt
  - DeepSpeed
  - OpenAI
  - Haystack
  - Langchain
  - Terraform
  - Streamlit
  - Vue.js

experience:
  - title: Freelancer
    company: self employed
    location: Munich, Germany
    start: Aug 2023
    end: present
    description: kohlmeyer-ai.com
  - title: Machine Learning Engineer
    company: SCAILEX GmbH
    logo: scailex.png
    location: Munich, Germany
    start: Dec 2021
    end: Aug 2023
    description: >
      I am responsible for the complete MLOps lifecycle including training.
      In this position, I was able to develop my skillset as a machine
      learning practitioner as well as a software engineer. Please refer to
      the "Projects" section for relevant projects and technologies used.
  - title: Data Scientist
    company: Atruvia AG
    logo: atruvia.png
    location: Munich, Germany
    start: Dec 2020
    end: Nov 2021
    description: >
      As a Data Scientist at an IT Service Provider for banks, I developed
      DL / ML applications in a banking context. Please refer to the
      "Projects" section for relevant projects and technologies used.
  - title: Auditor Banks & Asset Management
    company: KPMG AG
    logo: kpmg.png
    location: Zurich, Switzerland
    start: Oct 2018
    end: Dec 2018
    description: ""
  - title: Trainee Audit Asset Management
    company: KPMG Société coopérative
    logo: kpmg.png
    location: Luxembourg, Luxembourg
    start: Feb 2018
    end: Aug 2018
    description: ""

education:
  - degree: Business Analytics M.Sc.
    university: Hochschule Düsseldorf
    description: "Grade: 1.5"
    start: 2019
    end: 2020
    icon: ""
  - degree: Finance, Accounting, Controlling, and Taxes B.Sc.
    university: Fachhochschule Dortmund
    description: "Grade: 1.4"
    start: 2014
    end: 2018
    icon: ""

languages:
  - German
  - English

certificates:
  - name: MLOps Engineering for Production
    issued_by: Coursera
  - name: Specialization NLP
    issued_by: Coursera
  - name: Deep Learning Specialization
    issued_by: Coursera
  - name: Tensorflow Developer
    issued_by: Google
  - name: Tensorflow Advanced Techniques
    issued_by: Coursera
  - name: Azure Data Scientist Associate
    issued_by: Microsoft

projects:
  - title: AI Lawyer Chatbot
    abstract: Research and prototyping of German LLM using RLHF in multi-node, multi-GPU environment
    description:
      industry: Legal Tech
      objective: >
        The core objective of this project was to conduct research and prototype an instruction-based, 
        German Legal Language Model (LLM) utilizing Reinforcement Learning from Human Feedback (RLHF). 
        This LLM was designed to possess advanced capabilities including comprehending legal cases, 
        discerning relevant legal contexts, and independently generating pertinent inquiries to gather 
        information crucial to a legal claim.
      approach: >
        The first challenge was to generate a good quality annotated instruction dataset to perform the
        RLHF training. Once the dataset was generated the next hurdle was to perform mult-node, 
        multi-GPU training of LLMs on AWS & Azure. Since RLHF was a brand new technique, I used and contributed
        to open-source libraries, such as chatllama by nebuly.ai (see https://github.com/nebuly-ai/nebuly/pull/316
        and https://github.com/nebuly-ai/nebuly/pull/326).
        Throughout this project I had to read, comprehend, and implement multiple
        state-of-the-art Machine Learning papers.
    categories:
      - LLM
      - RLHF
      - Machine Learning
    techStack:
      - AWS
      - Huggingface
      - PyTorch
      - DeepSpeed
      - OpenAI
      - AWS Sagemaker
      - Azure
    duration: 3 months
    image: ai-lawyer.png
  - title: Paper Q&A Web Application
    abstract: >-
      Enhancement of LLM text generation using contextual information to enable
      fact-based question answering to quickly and efficiently understand research papers
      and be able to look up information
    description:
      industry: Personal Use
      objective: >
        The era of Large Language Models (LLM) has come and with the hype and the current power of
        innovation comes a huge flood of new developments both in proprietary context as well as in the
        open source world. To be able to always be up to date and to deliver state of the art solutions
        as a Machine Learning Engineer / Data Scientist, it is necessary to quickly understand whether a paper
        is relevant, understand the content of the paper, and be able to look up certain facts quickly.
        In the sense of the saying "fight fire with fire", let's use LLMs to understand LLMs (wink emoji).
      approach: >
        The crux is to intelligently incorporate the available context information like a specific or even
        multiple paper(s) into an LLM`s text generation. The context has to be chunked into processable units,
        relevant context has to be selected, and we have to ensure that the answer is fact-based and not
        hallucinated by the LLM.
        To achieve this, I decided to use deepset's GenerativeQAPipeline along with an OpenAIAnswerGenerator.
        There are other LLM pipelining tool's like LangChain, however, for this project I decided to go for 
        deepset as I have used it before and save LangChain for my next project. Using FAISS,
        my sentence level chunked papers will be embedded and stored in a vector database. This allows to retrieve
        relevant context using cosine similiarity between the embedded query vector and the respective context
        vectors. There are still adjustments to be implement to ensure factual correctness and further improve
        the context retrieval, but my streamlit app that also displays the retrieved context matches enables the
        user to perform sanity checks on the answer or even look up the actual text paragraphs in the original paper.
      result: The streamlit app including terraform IaC for deployment on AWS can be found in the linked GitHub repo.
      deployment: AWS ECR + ECS incl. custom domain on AWS Route 53 and AWS Cognito authorization
    categories:
      - Web Application
      - Machine Learning
      - LLM
      - Retrieval Augmented Generation
      - CICD
    techStack:
      - HuggingFace
      - Streamlit
      - OpenAI
      - Azure
      - Deepset
      - HayStack
      - Terraform
      - AWS Cloudfront
      - AWS EC2
      - AWS ECR
      - AWS Cognito
    duration: 3 days
    githubLink: https://github.com/EikeKohl/paperqa-web-app
    mediumLink: https://medium.com/@EKohlmeyer/deploying-a-streamlit-web-app-on-aws-with-authentication-using-aws-cognito-a-comprehensive-guide-1da9e7ae4726
    image: paperqa.png
  - title: Multi Stage Verdict Analysis Web Application using ChatGPT
    abstract: >-
      Web application for the analysis of incoming verdicts to formulate statements of appeal
      based on the verdicts content.
    description:
      industry: Legal Tech
      objective: >
        If a lawyer wants to appeal for a verdict, they have to provide reasons in a statement of appeal.
        To do so, the critical text passages in the verdict have to be identified and the statement has to be written.
        This can be a time consuming task as the verdicts are often very complex and long texts. The goal of
        the project was to decrease the manual effort necesary by increasing the level of automation
      approach: >
        The idea was to first identify relevant text passages in the input verdict using regex.
        Then I implemented a prompt chain, i.e. a multi stage ChatGPT prompting approach to first analyse the verdict
        regarding critical text passages through well designed prompt engineering and, based on the analysis, summarize
        the findings to formulate fitting statements of appeal.
      result: >
        Results are generated once a verdict arrives so that the app loads the pre generated results to enable
        the user to quickly fact check the analysis summary to approve the statement of appeal.
      deployment: AWS ECR + ECS incl. custom domain on AWS Route 53 and AWS Cognito authorization
    categories:
      - Web Application
      - Machine Learning
      - LLM
      - Retrieval Augmented Generation
      - CICD
      - Prompt Engineering
    techStack:
      - HuggingFace
      - Streamlit
      - OpenAI
      - Azure
      - LangChain
      - HayStack
      - Terraform
      - AWS Cloudfront
      - AWS EC2
      - AWS ECR
      - AWS Cognito
    duration: 3 months
    image: information-retrieval.png
  - title: Information Extraction
    abstract:  >-
      Training and deployment of information extraction models, 
      including Named Entity Recognition in the legal domain, using transformers with MLflow on Sagemaker.
    description:
      industry: Legal Tech
      objective: >
        The primary objective of this project was to establish a comprehensive pipeline for training, 
        evaluating, deploying, and monitoring information extraction models. 
        Within the context of the legal domain, the focus was on implementing Named Entity Recognition (NER) 
        techniques to accurately extract crucial details from various forms of correspondence, 
        including those from clients, courts, and insurance entities.
      approach: >
        Leveraging cutting-edge technology, I employed transformers-based architectures and devised a BiLSTM-CRF 
        ensemble model approach. This amalgamation allowed for enhanced contextual understanding and 
        robust entity recognition. The ensemble method aimed to leverage the strengths of both 
        architectures to attain more accurate NER outcomes.
        To achieve optimal results, extensive experiments were carried out. Model training experiments were 
        executed on Sagemaker, harnessing its scalability and efficiency. The training process was managed 
        through MLflow, allowing for systematic tracking of experiments, facilitating transparency, 
        reproducibility, and informed decision-making.
      deployment: AWS Lambda + AWS SNS / SQS
    categories:
      - Machine Learning
      - CICD
      - MLOps
    techStack:
      - Huggingface
      - PyTorch
      - AWS Lambda
      - MLflow
      - AWS Sagemaker
      - GitLab
    duration: 1.5 years
    image: information-extraction.png
  - title: Document Classification
    abstract: >
      Training, Evaluation, and Deployment of document classification models for a legal
      tech company with high accuracy.
    description:
      industry: Legal Tech
      objective: >
        Input and output management for correspondence with clients, insurers, and courts constitutes 
        a significant cost factor for legal professionals and law firms in Germany. 
        The initial stride towards automating incoming correspondence involves the automatic identification 
        of document types, enabling subsequent <b>document-specific</b> processes to be executed flawlessly and 
        efficiently. The objective of the project was thus to achieve a highly precise machine 
        learning-based classification of a substantial volume of incoming documents.
      approach: >
        Certain subsets of document types were received through specific channels, thus to enhance the 
        accuracy of classification outcomes, channel-specific models were trained. In addition to 
        state-of-the-art transformer architectures, simpler document embedding-based baseline models 
        were employed. Among these baseline models, one model prevailed over the transformer models 
        due to factors such as training and inference time, model size, and performance. The training 
        experiments were conducted using Sagemaker and tracked within MLflow.
      result: 95% accuracy with an automation rate of 80 % of 500,000+ documents
      deployment: AWS Lambda + AWS SNS / SQS
    categories:
      - Machine Learning
      - CICD
      - MLOps
    techStack:
      - Huggingface
      - PyTorch
      - AWS Lambda
      - MLflow
      - AWS Sagemaker
      - GitLab
    duration: 1.5 years
    image: document-classification.png

recommendations:
  - name: LinkedIn Member
    title: Senior Machine Learning Engineer
    relation: Former Team Colleague
    text: >-
      I had the privilege of working alongside Eike on several challenging machine learning projects, 
      and I wholeheartedly recommend him for his exceptional skills and dedication. 
      Throughout our collaboration, he consistently impressed me with his ability to effectively 
      solve real-world problems. Eike demonstrated remarkable problem-solving abilities, tackling 
      intricate issues with perseverance and ingenuity. His meticulous attention to detail and commitment 
      to producing high-quality results were truly commendable. Moreover, his exceptional teamwork and 
      effective communication skills greatly contributed to the success of our projects. 
      It was a pleasure working with Eike.
  - name: Rail Chamidullin
    title: Machine Learning Engineer
    relation: Former Team Colleague
    text: >-
      I worked with Eike on Machine Learning projects at SCAILEX (legal tech). 
      He helped me a lot to get started and to understand internal processes for NLP-based automation. 
      Eike is a very dedicated and productive person. He took extra steps to gain new skills and develop 
      more efficient solutions for the team. It was a pleasure collaborating with Eike, and 
      I highly recommend his expertise.